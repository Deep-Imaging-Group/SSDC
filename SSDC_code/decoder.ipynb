{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import cnn as model\n",
    "import config\n",
    "import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"Data\")\n",
    "input_image = scipy.io.loadmat(os.path.join(DATA_PATH, config.dataset_file_name))[config.dataset_mat_name]\n",
    "label_image = scipy.io.loadmat(os.path.join(DATA_PATH, config.dataset_gt_file_name))[config.dataset_gt_mat_name]\n",
    "\n",
    "\n",
    "height = label_image.shape[0]\n",
    "width = label_image.shape[1]\n",
    "channels = input_image.shape[2]\n",
    "\n",
    "\n",
    "PATCH_SIZE = config.patch_size\n",
    "class_num = config.num_classes\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(height)\n",
    "print(width)\n",
    "print(channels)\n",
    "print(input_image.shape)\n",
    "print(label_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling Down the image to 0 - 1\n",
    "input_image = np.pad(input_image, ((PATCH_SIZE//2, PATCH_SIZE//2), (PATCH_SIZE//2, PATCH_SIZE//2), (0, 0)), 'symmetric')\n",
    "input_image = input_image.astype(float)\n",
    "input_image -= np.min(input_image)\n",
    "input_image /= np.max(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_array(data):\n",
    "    mean_arr = data.reshape(data.shape[0], data.shape[1]*data.shape[2])\n",
    "    mean_arr = np.mean(mean_arr, axis = 1)\n",
    "    return np.array(mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    #to [channel,size,size]\n",
    "    transpose_array = data.transpose((2,0,1))\n",
    "\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = transpose_array[:, height_slice, width_slice]\n",
    "\n",
    "    mean = mean_array(transpose_array)\n",
    "    \n",
    "    mean_patch = np.subtract(patch, mean.reshape(-1,1,1))\n",
    "\n",
    "    return mean_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_inputs():\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(None, model.IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(None))\n",
    "    is_training = tf.placeholder(dtype=tf.bool)\n",
    "    return images_placeholder, labels_placeholder, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, batch_size, images_pl, labels_pl, is_training, TF):\n",
    "    images_feed, labels_feed = data_set.next_batch(batch_size)\n",
    "    feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "      is_training: TF,\n",
    "    }\n",
    "    return feed_dict, labels_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            is_training,\n",
    "            data_set):\n",
    "\n",
    "    predict_image = np.zeros((height,width))\n",
    "    \n",
    "    # run one epoch of eval.\n",
    "    steps_per_epoch = data_set.num_examples // batch_size\n",
    "    num_rest_examples = data_set.num_examples - steps_per_epoch * batch_size\n",
    "    total = 0\n",
    "    for step in range(steps_per_epoch):\n",
    "        feed_dict, labels_feed = fill_feed_dict(data_set,\n",
    "                                   batch_size,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder,\n",
    "                                   is_training,\n",
    "                                   False,)\n",
    "        prediction = sess.run(eval_correct, feed_dict=feed_dict)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            predict_image[total//width][total%width] = prediction[i]\n",
    "            total = total + 1\n",
    "    \n",
    "    if ( num_rest_examples != 0 ):\n",
    "        feed_dict, labels_feed = fill_feed_dict(data_set,\n",
    "                                   num_rest_examples,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder,\n",
    "                                   is_training,\n",
    "                                   False,)\n",
    "        prediction = sess.run(eval_correct, feed_dict=feed_dict)\n",
    "        for i in range(num_rest_examples):\n",
    "            predict_image[total//width][total%width] = prediction[i]\n",
    "            total = total + 1\n",
    "            \n",
    "    return predict_image\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(matrix):\n",
    "    matrix_sum_col = np.zeros(class_num)\n",
    "    matrix_sum_row = np.zeros(class_num)\n",
    "    diagonal_sum = 0\n",
    "    total_num = 0\n",
    "    for i in range(class_num):\n",
    "        diagonal_sum += matrix[i][i]\n",
    "        for j in range(class_num):\n",
    "            matrix_sum_col[j] += matrix[i][j]\n",
    "            matrix_sum_row[i] += matrix[i][j]\n",
    "            total_num += matrix[i][j]\n",
    "\n",
    "    oa = diagonal_sum / total_num\n",
    "    aa = 0\n",
    "    print('class#\\tright\\ttest\\trate')\n",
    "    for i in range(class_num):\n",
    "        prec_per_class = matrix[i][i] / matrix_sum_row[i]\n",
    "        aa += prec_per_class\n",
    "        print('%d\\t%d\\t%d\\t%.5f' % (i+1, int(matrix[i][i]), int(matrix_sum_row[i]),prec_per_class))\n",
    "    aa = aa / class_num\n",
    "\n",
    "    kappa_temp = 0\n",
    "    for i in range(class_num):\n",
    "        kappa_temp += matrix_sum_col[i] * matrix_sum_row[i]\n",
    "    kappa = (total_num*diagonal_sum-kappa_temp) / (total_num*total_num-kappa_temp)\n",
    "   \n",
    "    print('  OA: %.5f' % oa)\n",
    "    print('  AA: %.5f' % aa)\n",
    "    print('  kappa: %.5f' % kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    \n",
    "    image_patch = []\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            image_patch.extend(Patch(input_image,i,j))\n",
    "\n",
    "    \n",
    "    image_patch = np.array(image_patch)\n",
    "    image_patch = image_patch.reshape(-1, channels, PATCH_SIZE, PATCH_SIZE)\n",
    "    \n",
    "    target = label_image.flatten()\n",
    "    target = np.transpose(target)\n",
    "\n",
    "    return image_patch, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder():\n",
    "    \n",
    "    model_name = DATA_PATH + '/record/' + config.dataset + '/cnn_t0-7X7.ckpt-299'\n",
    "                               \n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        images_placeholder, labels_placeholder, is_training = placeholder_inputs()\n",
    "\n",
    "        logits = model.inference(images_placeholder, is_training)\n",
    "        \n",
    "        predict = model.predicting(logits)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        sess = tf.Session()\n",
    "\n",
    "        saver.restore(sess,model_name)\n",
    "\n",
    "                    \n",
    "        predict_image = do_eval(sess,\n",
    "                                predict,\n",
    "                                images_placeholder,\n",
    "                                labels_placeholder,\n",
    "                                is_training,\n",
    "                                datasets)\n",
    "\n",
    "        return predict_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_patch, target = create_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del datasets\n",
    "datasets = input_data.DataSet(image_patch, target)\n",
    "predict_image = decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix = np.zeros((class_num,class_num))\n",
    "label_image = label_image.astype(int)\n",
    "predict_image = predict_image.astype(int)\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        if(label_image[i][j] != 0):\n",
    "            matrix[label_image[i][j]-1][predict_image[i][j]] += 1\n",
    "\n",
    "calculate_precision(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = np.asarray( [[0, 0, 0],               \n",
    "                      [255, 0, 0],         \n",
    "                      [0, 255, 0],       \n",
    "                      [0, 0, 255],\n",
    "                      [255, 255, 0],\n",
    "                      [255, 0, 255],\n",
    "                      [0, 255, 255],\n",
    "                      [0, 170, 170],\n",
    "                      [170, 0, 170],\n",
    "                      [170, 170, 0],\n",
    "                      [127, 0, 255],\n",
    "                      [0, 127, 255],\n",
    "                      [255, 127, 0],\n",
    "                      [127, 0, 0],\n",
    "                      [0, 127, 0],\n",
    "                      [0, 0, 127],\n",
    "                      [127, 127, 127]], dtype='int32')\n",
    "\n",
    "# cmap = np.asarray( [[0, 0, 0],               \n",
    "#                        [255, 0, 0],         \n",
    "#                        [0, 255, 0],       \n",
    "#                        [0, 0, 255],\n",
    "#                        [255, 255, 0],\n",
    "#                        [255, 0, 255],\n",
    "#                        [0, 255, 255],\n",
    "#                        [0, 170, 170],\n",
    "#                        [170, 0, 170],\n",
    "#                        [170, 170, 0]], dtype='int32')\n",
    "y_rgb = cmap[predict_image.astype(int)+1, :]\n",
    "y_image = y_rgb.reshape(height, width, 3)\n",
    "scipy.misc.imsave(DATA_PATH + '/record/' + config.dataset + '/cnn.png' , y_image)\n",
    "\n",
    "y_rgb = cmap[label_image.astype(int), :]\n",
    "y_image = y_rgb.reshape(height, width, 3)\n",
    "scipy.misc.imsave(DATA_PATH + '/record/' + config.dataset + '/label.png' , y_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
